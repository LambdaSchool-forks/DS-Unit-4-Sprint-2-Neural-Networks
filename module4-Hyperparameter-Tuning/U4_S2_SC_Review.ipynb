{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture\n",
    "\n",
    "There are 3 layers in a typical NN:\n",
    "- Input Layer\n",
    "- Hidden Layers\n",
    "- Output Layer (nodes - correspond to the number of outputs)\n",
    "\n",
    "##### Each layer is made up of n individual neurons (aka activation units) which have a corresponding weight and bias.\n",
    "\n",
    "#### What process occurs in a neural network?\n",
    "The input layer receives input from our data (1 node per feature in our dataset). A signal from the input layer gets passed into the next layer (hidden layer), each input is multipled by the weight of that input, we add a bias term to the weighted sum of those inputs and weights, then we activate the weighted sum plus the bias using the activation function, squishifying it into  a probability, then we pass that activation value into the next layer\n",
    "\n",
    "#### A signal is passed through the network by:\n",
    " - Taking in inputs from the training data (or previous layer)\n",
    " - Multiplying each input by its corresponding weight (think arrow/connecting line)\n",
    " - Adding a bias to this weighted some of inputs and weights\n",
    " - Activating this weighted sum + bias by squishifying it with sigmoid or some other activation function. With a single perceptron with three inputs, calculating the output from the node is done like so:\n",
    "\\begin{align}\n",
    " y = sigmoid(\\sum(weight_{1}input_{1} + weight_{2}input_{2} + weight_{3}input_{3}) + bias)\n",
    "\\end{align}\n",
    " - this final activated value is the signal that gets passed onto the next layer of the network.\n",
    "\n",
    "\n",
    "\n",
    "#### How to train a neural network:\n",
    "0. Pick a network architecture\n",
    "   - No. of input units = No. of features\n",
    "   - No. of output units = Number of Classes (or expected targets)\n",
    "   - Select the number of hidden layers and number of neurons within each hidden layer\n",
    "1. Randomly initialize weights\n",
    "2. Implement forward propagation to get $h_{\\theta}(x^{(i)})$ for any $x^{(i)}$\n",
    "3. Implement code to compute a cost function $J(\\theta)$\n",
    "4. Implement backpropagation to compute partial derivatives $\\frac{\\delta}{\\delta\\theta_{jk}^{l}}{J(\\theta)}$\n",
    "5. Use gradient descent (or other advanced optimizer) with backpropagation to minimize $J(\\theta)$ as a function of parameters $\\theta\\$\n",
    "6. Repeat steps 2 - 5 until cost function is 'minimized' or some other stopping criteria is met. One pass over steps 2 - 5 is called an iteration or epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Perceptron From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df = df.dropna()\n",
    "\n",
    "# encode categorical features\n",
    "dict = {'female':0, 'male':1}\n",
    "df['Sex'] = df['Sex'].map(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name  Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    1  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut    0   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth    0  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train, test = train_test_split(df, test_size=0.2, random_state = 22)\n",
    "\n",
    "# features and target\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "# features = ['Pclass']\n",
    "target = 'Survived'\n",
    "\n",
    "# X, y vectors\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 5\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # random randn creates a draw along the standard normal distribution\n",
    "        # create a 5 x 1 matrix \n",
    "        self.weights1 = np.random.randn(self.inputs, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 /(1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward. \n",
    "        aka 'predict'\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.weighted_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.weighted_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = self.feed_forward(X)\n",
    "        predictions = [1 if i>0.5 else 0 for i in predictions]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.99897142e-07,  7.99897142e-07, -9.99999200e-01, -9.99999200e-01,\n",
       "        7.99897142e-07, -9.99999200e-01,  7.99897142e-07,  7.99897142e-07,\n",
       "        7.99897142e-07,  7.99897142e-07,  7.99897142e-07,  7.99897142e-07,\n",
       "       -9.99999200e-01, -9.99999200e-01,  7.99897142e-07,  7.99897142e-07,\n",
       "        7.99897142e-07,  7.99897142e-07,  7.99897142e-07,  7.99897142e-07,\n",
       "        7.99897142e-07,  7.99897142e-07,  7.99897142e-07,  7.99897142e-07,\n",
       "        7.99897142e-07, -9.99999200e-01, -9.99999200e-01,  7.99897142e-07,\n",
       "       -9.99999200e-01, -9.99999200e-01,  7.99897142e-07,  7.99897142e-07,\n",
       "        7.99897142e-07,  7.99897142e-07,  7.99897142e-07,  7.99897142e-07,\n",
       "       -9.99999200e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.values - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7297297297297297\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Neural Network\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Make predictions \n",
    "y_pred = nn.predict(X_test.values)\n",
    "\n",
    "# Test Accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 5\n",
    "        self.hiddenNodes = 3\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # random randn creates a draw along the standard normal distribution\n",
    "        # create a 5 x 3 matrix \n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        \n",
    "        # create a 3 x 1 matrix \n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "      \n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 /(1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward. \n",
    "        aka 'predict'\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.weighted_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activation of input => hidden\n",
    "        self.activated_sum = self.sigmoid(self.weighted_sum)\n",
    "        \n",
    "        # Weighted sum of hidden layer => output layer\n",
    "        self.weighted_sum = np.dot(self.activated_sum, self.weights2)\n",
    "        \n",
    "        # Final activation of output - hidden layer => output layer\n",
    "        self.activated_output = self.sigmoid(self.weighted_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = self.feed_forward(X)\n",
    "        predictions = [1 if i>0.5 else 0 for i in predictions]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.6756756756756757\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Neural Network\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Make predictions \n",
    "y_pred = nn.predict(X_test.values)\n",
    "\n",
    "# Test Accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron w/ Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 5\n",
    "        self.hiddenNodes = 3\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # random randn creates a draw along the standard normal distribution\n",
    "        # create a 5 x 3 matrix \n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        \n",
    "        # create a 3 x 1 matrix \n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "      \n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 /(1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward. \n",
    "        aka 'predict'\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.weighted_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activation of input => hidden\n",
    "        self.activated_sum = self.sigmoid(self.weighted_sum)\n",
    "        \n",
    "        # Weighted sum of hidden layer => output layer\n",
    "        self.weighted_sum = np.dot(self.activated_sum, self.weights2)\n",
    "        \n",
    "        # Final activation of output - hidden layer => output layer\n",
    "        self.activated_output = self.sigmoid(self.weighted_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = self.feed_forward(X)\n",
    "        predictions = [1 if i>0.5 else 0 for i in predictions]\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def backward(self, X,y,o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in Output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Appy  Derivative of Sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # z2 error: how much our hidden\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        # How much of that \"far off\" can be explained by the hidden => output weights\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        \n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # o is output\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7297297297297297\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Neural Network\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Make predictions \n",
    "y_pred = nn.predict(X_test.values)\n",
    "\n",
    "# Test Accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the different types of activation functions and when are they useful?\n",
    "- Linear\n",
    "- Sigmoid\n",
    "- Relu\n",
    "- Leaky Relu\n",
    "- Tanh\n",
    "- Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differnt types of loss metrics and when are they useful?\n",
    "- binary_crossentropy\n",
    "- categorical_crossentropy\n",
    "- binary_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
